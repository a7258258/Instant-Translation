import sounddevice as sd
import numpy as np
import whisper
import librosa
from deep_translator import GoogleTranslator

model = whisper.load_model("medium")
translator = GoogleTranslator(source='auto', target='zh-TW')

sample_rate = 48000
device_id = 23   # CABLE Output
chunk_duration = 10

print("ğŸ™ï¸ é–‹å§‹å³æ™‚ç¿»è­¯ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
5
while True:
    print("âºï¸ éŒ„éŸ³ä¸­...")
    recording = sd.rec(int(chunk_duration * sample_rate),
                       samplerate=sample_rate,
                       channels=2,
                       dtype='float32',
                       device=device_id)
    sd.wait()

    # è½‰å–®è²é“
    audio_chunk = librosa.to_mono(recording.T)
    audio_chunk = librosa.resample(audio_chunk, orig_sr=sample_rate, target_sr=16000)

    # Whisper è¾¨è­˜
    result = model.transcribe(audio_chunk, fp16=False)

    english_text = result["text"].strip()

    if english_text:
        print(f"\nğŸ—£ï¸ è‹±æ–‡è¾¨è­˜çµæœï¼š{english_text}")
        translated = translator.translate(english_text)
        print(f"ğŸŒ ä¸­æ–‡ç¿»è­¯ï¼š{translated}\n")
    else:
        print("ğŸ¤· æ²’æœ‰è¾¨è­˜åˆ°èªéŸ³å…§å®¹")